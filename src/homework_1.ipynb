{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a0b68a",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "- **Questions**: [Here](../data/homework_1/HW.pdf)\n",
    "- **Answer Set** : NO. 01\n",
    "- **Full Name** : Fatemeh Karimi Barikarasfi\n",
    "- **Student Code** : 610301060\n",
    "\n",
    "The goal is Sentiment Analysis using NGram Language Model, the dataset is [IMDB](https://drive.google.com/drive/folders1F88DpdjwHRAfFko0Z4J_SnRas2PYRU4j) which contains people ideas and indicate the aspect of the idea which means that is the idea positive or negative.\n",
    "\n",
    "## Importing Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4444c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9a712",
   "metadata": {},
   "source": [
    "## importing data\n",
    "\n",
    "Load train, validation, and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "280cf293",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train.pickle', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "\n",
    "with open('x_test.pickle', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "\n",
    "with open('x_val.pickle', 'rb') as f:\n",
    "    x_val = pickle.load(f)\n",
    "\n",
    "\n",
    "y_train = numpy.loadtxt('y_train.txt', dtype='int32')\n",
    "y_val = numpy.loadtxt('y_val.txt', dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096585f",
   "metadata": {},
   "source": [
    "## preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46022e0",
   "metadata": {},
   "source": [
    "Do removing unwanted digits, unwanted punchuations, lowering all characters, word tokenization, removing stopwords, and stemming as preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b68097",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_digit=['0','1','2','3','4','5','6','7','8','9']\n",
    "unwanted_punc=['<br />', '...',',','\"','=','@','&','%',',',':','\\\\','$','^','<','>','{','}',';','\\n','\\t','(',')','[',']','/','*','+','#','-','_','|']\n",
    "# removing unwanted digits\n",
    "for digit in unwanted_digit:\n",
    "    x_train = [sent.replace(digit, \"\") for sent in x_train]\n",
    "    x_test = [sent.replace(digit, \"\") for sent in x_test]\n",
    "    x_val = [sent.replace(digit, \"\") for sent in x_val]\n",
    "# removing unwanted punchuations\n",
    "for punc in unwanted_punc:\n",
    "    x_train = [sent.replace(punc, \"\") for sent in x_train]\n",
    "    x_test = [sent.replace(punc, \"\") for sent in x_test]\n",
    "    x_val = [sent.replace(punc, \"\") for sent in x_val]\n",
    "# lowering all characters\n",
    "x_train = [sent.lower() for sent in x_train]\n",
    "x_test = [sent.lower() for sent in x_test]\n",
    "x_val = [sent.lower() for sent in x_val]\n",
    "# word tokenization\n",
    "x_train = [nltk.word_tokenize(sent) for sent in x_train]\n",
    "x_test = [nltk.word_tokenize(sent) for sent in x_test]\n",
    "x_val = [nltk.word_tokenize(sent) for sent in x_val]\n",
    "# removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = [w for w in x_train[i] if w not in stop_words]\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i] = [w for w in x_test[i] if w not in stop_words]\n",
    "for i in range(len(x_val)):\n",
    "    x_val[i] = [w for w in x_val[i] if w not in stop_words]\n",
    "# stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = [stemmer.stem(w) for w in x_train[i]]\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i] = [stemmer.stem(w) for w in x_test[i]]\n",
    "for i in range(len(x_val)):\n",
    "    x_val[i] = [stemmer.stem(w) for w in x_val[i]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c15a9",
   "metadata": {},
   "source": [
    "## Preparing data for trainig and testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "342c5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "x_train_positive = nltk.sent_tokenize(\" \".join(flatten([x_train[i] for i in range(0, len(x_train)) if y_train[i] == 1])))\n",
    "x_train_negative = nltk.sent_tokenize(\" \".join(flatten([x_train[i] for i in range(0, len(x_train)) if y_train[i] == 0])))\n",
    "\n",
    "x_val_sents = [\" \".join(item) for item in x_val]\n",
    "x_val_positive_sents = [x_val_sents[i] for i in range(len(x_val_sents)) if y_val[i] == 1]\n",
    "x_val_negative_sents = [x_val_sents[i] for i in range(len(x_val_sents)) if y_val[i] == 0]\n",
    "\n",
    "x_test_sents = [\" \".join(item) for item in x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443d5d9",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Create NGrams Models with N = 1, 2, 3, 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f5001",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl\"> در این مرحله مدل های گفته شده در صورت سوال ، پیاده سازی شده است . برای فرآیند smoothing از تکنیک laplace استفاده شده است . </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c525081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2debb0",
   "metadata": {},
   "source": [
    "## unigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a151c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_model_positive = Laplace(1)\n",
    "uni_model_positive.fit(*padded_everygram_pipeline(1, x_train_positive))\n",
    "\n",
    "uni_model_negative = Laplace(1)\n",
    "uni_model_negative.fit(*padded_everygram_pipeline(1, x_train_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bcb51b",
   "metadata": {},
   "source": [
    "## bigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b744ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_model_positive = Laplace(2)\n",
    "bi_model_positive.fit(*padded_everygram_pipeline(2, x_train_positive))\n",
    "\n",
    "bi_model_negative = Laplace(2)\n",
    "bi_model_negative.fit(*padded_everygram_pipeline(2, x_train_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f63d9",
   "metadata": {},
   "source": [
    "## trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92950be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_model_positive = Laplace(3)\n",
    "tri_model_positive.fit(*padded_everygram_pipeline(3, x_train_positive))\n",
    "\n",
    "tri_model_negative = Laplace(3)\n",
    "tri_model_negative.fit(*padded_everygram_pipeline(3, x_train_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0e7ae",
   "metadata": {},
   "source": [
    "## quadgram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0b5b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_model_positive = Laplace(4)\n",
    "quad_model_positive.fit(*padded_everygram_pipeline(4, x_train_positive))\n",
    "\n",
    "quad_model_negative = Laplace(4)\n",
    "quad_model_negative.fit(*padded_everygram_pipeline(4, x_train_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc7065",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c931e4",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl\"> در این قسمت بیشترین ngram تکرار شده در هر مدل نشان داده شده است . </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01f5b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "553e39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = [w for w in x_train[i] if w not in ['.', '!', '?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e4e4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p = list(flatten([x_train[i] for i in range(len(x_train)) if y_train[i] == 1]))\n",
    "x_n = list(flatten([x_train[i] for i in range(len(x_train)) if y_train[i] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9f0e4",
   "metadata": {},
   "source": [
    "## most frequent n-gram of each models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551f2c8",
   "metadata": {},
   "source": [
    "### unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4895d24",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e3dc839",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_list_p = list(ngrams(x_p, 1))\n",
    "freq_dist_uni_p = FreqDist(unigram_list_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a87cdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({(\"'s\",): 31422, ('film',): 24453, ('movi',): 21663, ('one',): 13605, (\"n't\",): 13366, ('like',): 10067, ('time',): 7804, ('good',): 7391, ('see',): 7201, ('charact',): 6915, ...})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_uni_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ddd892",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "501b65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_list_n = list(ngrams(x_n, 1))\n",
    "freq_dist_uni_n = FreqDist(unigram_list_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c66592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({(\"'s\",): 29613, ('movi',): 28004, ('film',): 21520, (\"n't\",): 19946, ('one',): 13018, ('like',): 12112, ('get',): 7700, ('make',): 7694, ('even',): 7671, ('would',): 7661, ...})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_uni_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd358318",
   "metadata": {},
   "source": [
    "### bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb4058",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1be88729",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list_p = list(ngrams(x_p, 2))\n",
    "freq_dist_bi_p = FreqDist(bigram_list_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fd026b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('ca', \"n't\"): 1436, ('film', \"'s\"): 910, ('one', 'best'): 801, ('watch', 'movi'): 662, (\"'ve\", 'seen'): 648, ('wo', \"n't\"): 611, (\"n't\", 'know'): 554, ('movi', \"'s\"): 523, ('even', 'though'): 513, ('look', 'like'): 491, ...})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_bi_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd97da",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e3a82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list_n = list(ngrams(x_n, 2))\n",
    "freq_dist_bi_n = FreqDist(bigram_list_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0911c193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('ca', \"n't\"): 2081, ('look', 'like'): 1399, (\"n't\", 'even'): 1150, ('could', \"n't\"): 1063, ('watch', 'movi'): 860, (\"n't\", 'know'): 822, ('wast', 'time'): 813, ('ever', 'seen'): 810, ('film', \"'s\"): 775, ('special', 'effect'): 721, ...})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_bi_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2aee9",
   "metadata": {},
   "source": [
    "### trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b1908",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "540bbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_list_p = list(ngrams(x_p, 3))\n",
    "freq_dist_tri_p = FreqDist(trigram_list_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d59c96f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({(\"'ve\", 'ever', 'seen'): 154, ('ca', \"n't\", 'help'): 108, ('new', 'york', 'citi'): 101, ('ca', \"n't\", 'wait'): 99, ('film', \"'ve\", 'seen'): 90, ('film', 'ever', 'made'): 84, ('one', 'best', 'movi'): 82, ('world', 'war', 'ii'): 78, ('base', 'true', 'stori'): 69, ('one', 'best', 'film'): 69, ...})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_tri_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752467a6",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22dfe369",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_list_n = list(ngrams(x_n, 3))\n",
    "freq_dist_tri_n = FreqDist(trigram_list_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6bdf4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({(\"'ve\", 'ever', 'seen'): 324, ('worst', 'movi', 'ever'): 259, ('ca', \"n't\", 'believ'): 193, (\"n't\", 'wast', 'time'): 189, ('movi', 'ever', 'seen'): 189, ('one', 'worst', 'movi'): 149, ('worst', 'film', 'ever'): 134, ('movi', \"'ve\", 'ever'): 128, ('ca', \"n't\", 'even'): 110, ('worst', 'movi', \"'ve\"): 109, ...})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_tri_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e3b2d",
   "metadata": {},
   "source": [
    "### quadgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95f7e6",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8aee0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_list_p = list(ngrams(x_p, 4))\n",
    "freq_dist_quad_p = FreqDist(quadgram_list_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57d95708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('ca', \"n't\", 'wait', 'see'): 38, ('movi', \"'ve\", 'ever', 'seen'): 29, ('film', \"'ve\", 'ever', 'seen'): 25, (\"'ve\", 'seen', 'long', 'time'): 19, ('one', 'best', 'movi', 'ever'): 18, ('one', 'best', 'movi', \"'ve\"): 17, ('best', 'movi', 'ever', 'made'): 15, ('ca', \"n't\", 'help', 'feel'): 15, ('ca', \"n't\", 'go', 'wrong'): 14, ('best', 'movi', \"'ve\", 'seen'): 14, ...})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_quad_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b5517",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf1a618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_list_n = list(ngrams(x_n, 4))\n",
    "freq_dist_quad_n = FreqDist(quadgram_list_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbacf421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('worst', 'movi', 'ever', 'seen'): 127, ('movi', \"'ve\", 'ever', 'seen'): 105, ('one', 'worst', 'movi', 'ever'): 77, ('worst', 'movi', \"'ve\", 'ever'): 75, ('worst', 'film', 'ever', 'seen'): 61, ('worst', 'movi', 'ever', 'made'): 51, ('film', \"'ve\", 'ever', 'seen'): 48, ('one', 'worst', 'film', 'ever'): 43, ('worst', 'film', 'ever', 'made'): 39, ('one', 'worst', 'movi', \"'ve\"): 39, ...})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_quad_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e3f65",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72eea74",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl\"> در این قسمت perplexity هر مدل محاسبه شده است . </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b6fd1",
   "metadata": {},
   "source": [
    "## perplexity of each models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6014410",
   "metadata": {},
   "source": [
    "### unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478564e",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f5b47df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.99999999999875"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_model_positive.perplexity(x_val_positive_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746f17c",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55049fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.99999999999947"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_model_negative.perplexity(x_val_negative_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedc059",
   "metadata": {},
   "source": [
    "### bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee98de",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a35c592a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0000000000047"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_model_positive.perplexity(x_val_positive_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724ed51",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99cbed82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.99999999999875"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_model_negative.perplexity(x_val_negative_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e8e09",
   "metadata": {},
   "source": [
    "### trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81cbfa4",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d99c9c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0000000000047"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_model_positive.perplexity(x_val_positive_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de6781",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d46f66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.99999999999875"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_model_negative.perplexity(x_val_negative_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4634b06",
   "metadata": {},
   "source": [
    "### quadgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a444e",
   "metadata": {},
   "source": [
    "#### positive feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e17df198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0000000000047"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_model_positive.perplexity(x_val_positive_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa482f2",
   "metadata": {},
   "source": [
    "#### negative feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07dc8c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.99999999999875"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_model_negative.perplexity(x_val_negative_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50402647",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64b350",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl\"> در این قسمت مدل های پیاده سازی شده ارزیابی شده است و دقت هرکدام print  شده است . </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d2ab0",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl\"> برای تشخیص کلاس هر نظر از معیار perplexity استفاده شده است زیرا این معیار متناسب با معکوس احتمال جمله می باشد و با توجه به این میتوان گفت هر مدلی که perplexity کمتری برای جمله داشته باشد آن جمله به کلاس آن مدل تعلق دارد . . </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe56273f",
   "metadata": {},
   "source": [
    "## evaluating each models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307e2d9",
   "metadata": {},
   "source": [
    "### unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2be2a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_positive_perplexities = [uni_model_positive.perplexity(sent) for sent in x_val_sents]\n",
    "uni_negative_perplexities = [uni_model_negative.perplexity(sent) for sent in x_val_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f4ba605",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_labels = [1 if uni_positive_perplexities[i] < uni_negative_perplexities[i] else 0 for i in range(len(y_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ed7630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.384\n"
     ]
    }
   ],
   "source": [
    "succs = 0\n",
    "for i in range(len(uni_labels)):\n",
    "    if uni_labels[i] == y_val[i]:\n",
    "        succs = succs + 1\n",
    "\n",
    "print(succs * 100 / len(uni_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42325f2",
   "metadata": {},
   "source": [
    "### bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2f72b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_positive_perplexities = [bi_model_positive.perplexity(sent) for sent in x_val_sents]\n",
    "bi_negative_perplexities = [bi_model_negative.perplexity(sent) for sent in x_val_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57dbc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_labels = [1 if bi_positive_perplexities[i] < bi_negative_perplexities[i] else 0 for i in range(len(y_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "914a9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.352\n"
     ]
    }
   ],
   "source": [
    "succs = 0\n",
    "for i in range(len(bi_labels)):\n",
    "    if bi_labels[i] == y_val[i]:\n",
    "        succs = succs + 1\n",
    "\n",
    "print(succs * 100 / len(bi_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba87d961",
   "metadata": {},
   "source": [
    "### trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1395d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_positive_perplexities = [tri_model_positive.perplexity(sent) for sent in x_val_sents]\n",
    "tri_negative_perplexities = [tri_model_negative.perplexity(sent) for sent in x_val_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a734190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_labels = [1 if tri_positive_perplexities[i] < tri_negative_perplexities[i] else 0 for i in range(len(y_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb58c0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.792\n"
     ]
    }
   ],
   "source": [
    "succs = 0\n",
    "for i in range(len(tri_labels)):\n",
    "    if tri_labels[i] == y_val[i]:\n",
    "        succs = succs + 1\n",
    "\n",
    "print(succs * 100 / len(tri_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3485e0",
   "metadata": {},
   "source": [
    "### quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f2b9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_positive_perplexities = [quad_model_positive.perplexity(sent) for sent in x_val_sents]\n",
    "quad_negative_perplexities = [quad_model_negative.perplexity(sent) for sent in x_val_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9691b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_labels = [1 if quad_positive_perplexities[i] < quad_negative_perplexities[i] else 0 for i in range(len(y_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bafdeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.112\n"
     ]
    }
   ],
   "source": [
    "succs = 0\n",
    "for i in range(len(quad_labels)):\n",
    "    if quad_labels[i] == y_val[i]:\n",
    "        succs = succs + 1\n",
    "\n",
    "print(succs * 100 / len(quad_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ec183",
   "metadata": {},
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a88fe",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl\"> با توجه به ارزیابی قسمت قبل بهترین مدل ، مدل unigram می باشد . </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c2a457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_positive_perplexities_test = [uni_model_positive.perplexity(sent) for sent in x_test_sents]\n",
    "uni_negative_perplexities_test = [uni_model_negative.perplexity(sent) for sent in x_test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f26dc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [1 if uni_positive_perplexities_test[i] < uni_negative_perplexities_test[i] else 0 for i in range(len(x_test_sents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d5a6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savetxt(\"y_test.csv\", test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
